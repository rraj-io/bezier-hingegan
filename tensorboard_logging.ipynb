{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326af651",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Extracting gifs and videos from Tensorbaord logging for Airfoil convergence\n",
    "\n",
    "* Use tensorboard's `event_accumulator`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4e3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00f3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard event file for each case\n",
    "\n",
    "event_paths = [\n",
    "    \"./trained_gan/2_10/logs/events.out.tfevents.1748680094.mars.ihs.uni-stuttgart.de.10977.0\",\n",
    "    \"./trained_gan/2_10/logs/events.out.tfevents.1748692205.snickers.ihs.uni-stuttgart.de.1735.0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c21a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image tags\n",
    "image_tag = 'Generated HydroFoils'\n",
    "\n",
    "# custom folder to save extracted images\n",
    "extracted_dir = \"./results/2_10/frames\"\n",
    "annotated_dir = \"./results/2_10/frames_annotated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f2a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if directory exists\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "os.makedirs(annotated_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a9dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "for event_path in event_paths:\n",
    "    ea = event_accumulator.EventAccumulator(event_path)\n",
    "    ea.Reload()\n",
    "    \n",
    "    if image_tag not in ea.Tags()['images']:\n",
    "        print(f\"tag '{image_tag}' not found in {event_path}. Skipping.\")\n",
    "        continue\n",
    "    # Extract images\n",
    "    images = ea.Images(image_tag)\n",
    "\n",
    "    for img_event in images:\n",
    "        step = img_event.step\n",
    "        img_array = np.frombuffer(img_event.encoded_image_string, dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        cv2.imwrite(f\"{extracted_dir}/hydrofoil_epoch_{step:05d}.png\", img)\n",
    "print(\"Images extracted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977b37d",
   "metadata": {},
   "source": [
    "## Upper part is still pending. I need to save all logging images for 1 training, irrespective of its size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc94540",
   "metadata": {},
   "source": [
    "# Model Architecture paramter size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f81817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load teh model \n",
    "from hydFoilGAN.gan import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a6bc552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters\n",
    "import torch\n",
    "LATENT_DIM = 2\n",
    "NOISE_DIM = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load model \n",
    "checkpoint = torch.load(\"./trained_gan/2_10/checkpoints/model_epoch_10000.pth\")\n",
    "\n",
    "#generator model\n",
    "model_G = Generator(latent_dim=LATENT_DIM,\n",
    "                    noise_dim=NOISE_DIM).to(device)\n",
    "#discriminator model\n",
    "model_D = Discriminator(latent_dim=LATENT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949d2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load generator and discriminator weights\n",
    "model_G.load_state_dict(checkpoint['model_G_state_dict'])\n",
    "model_D.load_state_dict(checkpoint['model_D_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c2866bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchsummary\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fcd8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]          13,312\n",
      "       BatchNorm1d-2                 [-1, 1024]           2,048\n",
      "         LeakyReLU-3                 [-1, 1024]               0\n",
      "            Linear-4                 [-1, 3072]       3,148,800\n",
      "       BatchNorm1d-5                 [-1, 3072]           6,144\n",
      "         LeakyReLU-6                 [-1, 3072]               0\n",
      "================================================================\n",
      "Total params: 3,170,304\n",
      "Trainable params: 3,170,304\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 12.09\n",
      "Estimated Total Size (MB): 12.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# generator summary Linear part\n",
    "summary(model_G.gen1, input_size=(LATENT_DIM+NOISE_DIM,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c71b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 128, 8, 3]         393,344\n",
      "       BatchNorm2d-2            [-1, 128, 8, 3]             256\n",
      "         LeakyReLU-3            [-1, 128, 8, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 64, 16, 3]          98,368\n",
      "       BatchNorm2d-5            [-1, 64, 16, 3]             128\n",
      "         LeakyReLU-6            [-1, 64, 16, 3]               0\n",
      "   ConvTranspose2d-7            [-1, 32, 32, 3]          24,608\n",
      "       BatchNorm2d-8            [-1, 32, 32, 3]              64\n",
      "         LeakyReLU-9            [-1, 32, 32, 3]               0\n",
      "================================================================\n",
      "Total params: 516,768\n",
      "Trainable params: 516,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.21\n",
      "Params size (MB): 1.97\n",
      "Estimated Total Size (MB): 2.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Summarize the conv transpose part (gen2)\n",
    "depth_cpw = 32*8\n",
    "dim_cpw = int((31 + 2)/8)\n",
    "summary(model_G.gen2, input_size=(depth_cpw, dim_cpw, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d18834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/rraj/venvs/py311/lib64/python3.11/site-packages/torch/nn/modules/conv.py:549: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /pytorch/aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv2d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 2, 200]             512\n",
      "       BatchNorm2d-2           [-1, 64, 2, 200]             128\n",
      "         LeakyReLU-3           [-1, 64, 2, 200]               0\n",
      "           Dropout-4           [-1, 64, 2, 200]               0\n",
      "            Conv2d-5          [-1, 128, 2, 200]          65,536\n",
      "       BatchNorm2d-6          [-1, 128, 2, 200]             256\n",
      "         LeakyReLU-7          [-1, 128, 2, 200]               0\n",
      "           Dropout-8          [-1, 128, 2, 200]               0\n",
      "            Conv2d-9          [-1, 256, 2, 200]         262,144\n",
      "      BatchNorm2d-10          [-1, 256, 2, 200]             512\n",
      "        LeakyReLU-11          [-1, 256, 2, 200]               0\n",
      "          Dropout-12          [-1, 256, 2, 200]               0\n",
      "           Conv2d-13          [-1, 512, 2, 200]       1,048,576\n",
      "      BatchNorm2d-14          [-1, 512, 2, 200]           1,024\n",
      "        LeakyReLU-15          [-1, 512, 2, 200]               0\n",
      "          Dropout-16          [-1, 512, 2, 200]               0\n",
      "          Flatten-17               [-1, 204800]               0\n",
      "           Linear-18                 [-1, 1024]     209,716,224\n",
      "      BatchNorm1d-19                 [-1, 1024]           2,048\n",
      "        LeakyReLU-20                 [-1, 1024]               0\n",
      "           Linear-21                    [-1, 1]           1,025\n",
      "           Linear-22                  [-1, 128]         131,200\n",
      "      BatchNorm1d-23                  [-1, 128]             256\n",
      "        LeakyReLU-24                  [-1, 128]               0\n",
      "           Linear-25                    [-1, 2]             258\n",
      "           Linear-26                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 211,229,957\n",
      "Trainable params: 211,229,957\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 13.31\n",
      "Params size (MB): 805.78\n",
      "Estimated Total Size (MB): 819.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# discriminator summary\n",
    "summary(model_D, input_size=(1,2,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc730179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
